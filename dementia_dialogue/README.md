# Dementia_dialogue
- å¤§æ­¦å…ˆç”Ÿã®å®Ÿé¨“æ‰‹ä¼ã„

## ç’°å¢ƒæ§‹ç¯‰ãƒ¡ãƒ¢
- local version (`dementia`)
    - https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/
    - pyenvãŒæ€ªã—ã„ã‚‰ã—ã„ã®ã§ã“ã‚Œã§ç’°å¢ƒæ§‹ç¯‰ã—ãŸ
    - `source dementia/bin/activate`
- server version (`dementia_cuda10`)
    - `qrsh -jc gpu-container_g1_dev -ac d=nvcr-pytorch-2003` # ã‚³ãƒ³ãƒ†ãƒŠã«å…¥ã‚‹
    - `source ./dementia_cuda10/bin/activate` # cuda10ã®venvä»®æƒ³ç’°å¢ƒã«å…¥ã‚‹

## log
### 3/24
- ä»Šã‚ã‚‹å¯¾è©±ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œç¾åœ¨ã€ã€Œéå»ã€ã€Œæœªæ¥ã€ã‚’è­˜åˆ¥ã™ã‚‹classifierã‚’[Transformers](https://github.com/huggingface/transformers)ã®éˆ´æœ¨mã•ã‚“ã®æ—¥æœ¬èªBERTã§ä½œã‚‹
    - `pip install transformers==2.4.1`
        - ERROR
            -   running build_rust
            error: Can not find Rust compiler
            ----------------------------------------
            ERROR: Failed building wheel for tokenizers
            Failed to build tokenizers
            - RustãŒãªã„ï¼Ÿã¿ãŸã„ãªã“ã¨è¨€ã£ã¦ã‚‹
            - From sourceã§ install ã—ã¦ã‚‚åŒã˜ã‚ˆã†ãªERRORã‚’åã
                - [Issue](https://github.com/huggingface/transformers/issues/2831)ã§ver2.4.1ã‚’å…¥ã‚Œã‚‹ã¨ã„ã„ã‚ˆï¼ã¨æ›¸ã„ã¦ã‚ã‚‹

    - ã¨ã‚Šã‚ãˆãšQuick Startã¨ã‹ã‚„ã‚‹ï¼Ÿ
    - ã“ã®å‰ãƒªãƒ„ã‚¤ãƒ¼ãƒˆã•ã‚Œã¦ã„ãŸ[Twitterã®ä½¿ã„æ–¹è¬›åº§](https://twitter.com/huggingface/status/1205283603128758277)ã¿ã‚‹ï¼Ÿ
        - å®Œå…¨ã«ã‚³ãƒ”ãƒ¼ã—ãŸã‚‚ã®ã‚’`sample.py`ã¨ã—ã¦ä½œæˆ

    - torch > 1.0.0ãŒå¿…è¦ãªã®ã§[pytorch](https://pytorch.org/)ã‚’install
    - `pip install torch torchvision`

    - `python sample.py`
        - pathãŒé–“é•ã£ã¦ã‚‹ã¨æ€’ã‚‰ã‚ŒãŸ
            - `bert-base-japanese-whole-word-masking`ã ã£ãŸ
        - MeCabãŒãªã„ã¨æ€’ã‚‰ã‚ŒãŸ
            - `pip install mecab-python3` 

### 3/29(Sun)
- å‹•ã„ãŸ

### 3/30(Mon)
- [(Part 2) tensorflow 2 ã§hugging faceã®transformerså…¬å¼ã®BERTæ—¥æœ¬èªå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’æ–‡æ›¸åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã«fine-tuningã™ã‚‹](https://tksmml.hatenablog.com/entry/2019/12/15/090900)
    - ã“ã‚Œã‚’è¦‹ã¤ã¤åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’fine-tuningã™ã‚‹

- å‰å‡¦ç†ã¨ã—ã¦ã€
    1.  å¤§æ­¦å…ˆç”Ÿã®ãƒ‡ãƒ¼ã‚¿ã‚’ã€Œç™ºè©±æ–‡, éå»ç­‰ã®ãƒ©ãƒ™ãƒ«ã€çš„ãªcsvã«æŠ½å‡º
    2. Mecab(ipadic)ã§åˆ†å‰²
    3. BertJapaneseTokeniserã§idåŒ–

#### 1. å¤§æ­¦å…ˆç”Ÿã®ãƒ‡ãƒ¼ã‚¿ã‚’ã€Œç™ºè©±æ–‡, éå»ç­‰ã®ãƒ©ãƒ™ãƒ«ã€çš„ãªcsvã«æŠ½å‡º
- `./data/annotationsã®ã‚³ãƒ”ãƒ¼2.csv`ã‹ã‚‰`script`ï¼ˆå®Ÿéš›ã®ç™ºè©±ï¼‰ã¨`time`ï¼ˆéå»ãƒ»ç¾åœ¨ãƒ»æœªæ¥ç­‰ã®annotationï¼‰ã‚’æŠ½å‡º
    - ã¤ã„ã§ã«idã¨file_idã‚‚
    - csvã£ã¦è¨€ã£ã¦ã‚‹ã‘ã©tsvã ã£ãŸ
    - æ–‡å­—ã‚³ãƒ¼ãƒ‰ãŒutf-16ã ã£ãŸ

- `annotations.csv`ã«ã¯å…¨ã¦ã®scriptã«å¯¾ã—ã¦timeãŒç¶²ç¾…çš„ã«ã¤ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„
    - åŸºæº–ã¯ï¼Ÿ -> è¤‡æ•°
        - å¯¾è±¡å¤–ãƒ•ãƒ©ã‚°ï¼ˆé‡è¤‡ç­‰ã§annotationã®å¯¾è±¡å¤–ã¨ã—ãŸï¼‰
        - time_impossibleï¼ˆæ™‚é–“ã®åˆ¤å®šãŒå›°é›£ï¼‰
            - ã“ã®ãƒ•ãƒ©ã‚°ãŸã¡ãŒã¤ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¦å­¦ç¿’ã™ã‚‹ã®ã‹ã€ãã‚Œã¨ã‚‚ãã‚Œã‚‰ã‚‚åŠ ãˆã¦å­¦ç¿’ã™ã‚‹ã®ã‹ã©ã£ã¡ï¼Ÿ
            - å¯¾è±¡å¤–ãƒ•ãƒ©ã‚°ã¯ã“ã®æ™‚é–“åˆ¤å®šå™¨ã«ã‹ã‘ã‚‹å‰ã«ã¤ã‘ã‚‰ã‚Œãã†ã ãŒã€ã€Œæ™‚é–“ã®åˆ¤å®šãŒå›°é›£ã€ã¯å³ã—ã„ã®ã§ã¯ï¼Ÿãã‚Œã‚‚ï¼ˆéˆ´æœ¨ã•ã‚“ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ã€Œè§£ç­”ä¸å¯èƒ½ã€ã‚’åˆ¤å®šã™ã‚‹ã€ã¿ãŸã„ãªæ„Ÿã˜ã§ï¼‰ï¼‰æ™‚é–“åˆ¤å®šå™¨ãŒå‡ºã™ä¸€ã¤ã®åˆ†é¡ã®å‡ºåŠ›ã¨ã—ã¦å…¥ã‚ŒãŸæ–¹ãŒè‰¯ã„ï¼Ÿ
            - ãã†ã„ã†ä»˜ã‘æ–¹ã§ã¯ãªã„ã€‚ã‚€ã—ã‚ã€Œéå»ã€ã¨ã‹ãŒä»˜ã„ã¦ã„ã‚‹è€…ã«å¯¾ã—ã¦flag=1ã‚’ç«‹ã¦ã¦ã„ã‚‹

        - **intention = ç™ºè¨€ã€ã®å ´åˆã€å…¨ã¦ã®annotationãŒã¤ã‘ã‚‰ã‚Œã¦ã„ãªã„**
            - éå»ç­‰ã‚’åˆ¤æ–­ã™ã‚‹å‰ã«ã€ã¾ãšintentionã‚’åˆ¤æ–­ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã®ã§ã¯ï¼Ÿï¼Ÿ
        - ã“ã†ã„ã†æ™‚ã«ã©ã†å®Ÿè£…ã™ã‚Œã°ã„ã„ã‹å›°ã£ãŸã‚‰optionåŒ–ã—ã‚ã£ã¦è¨€ã£ã¦ãŸ
        - ã®ã§argparseã‚’å°å…¥ã—ã€ã©ã®annotationã‚’ã¤ã‘ã‚‹ã‹optionã§é¸ã¹ã‚‹ã‚ˆã†ã«ã—ãŸ
    
- `extract_data.py`ã¨ã„ã†ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºç”¨ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ
    - `python extract_data.py ./data/scripts_time.tsv -t `
    - `python extract_data.py ./data/scripts_time_intention.tsv -t -i`
    - ã‚’ãã‚Œãã‚Œå®Ÿè¡Œã—ã€scriptã¨timeã ã‘ã¤ã„ãŸãƒ‡ãƒ¼ã‚¿(scripts_time.tsv)ã€scriptã¨time, intentionãŒä»˜ã„ãŸãƒ‡ãƒ¼ã‚¿(scripts_time_intention.tsv)ã‚’ä½œæˆ

- `tokenize_data.py`ã¨ã„ã†ãƒ‡ãƒ¼ã‚¿tokenizeç”¨ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ
    - scriptã®Mecabåˆ†å‰²
    - timeãƒ©ãƒ™ãƒ«IDåŒ–
        - timeãƒ©ãƒ™ãƒ«ã®ç•°ãªã‚Šæ•°ã¯10ï¼ˆID: 0~9ï¼‰
            - `{'éå»', 'éå»-æœ€è¿‘', 'æœ€è¿‘ï¼ˆ1ã‹æœˆä»¥å†…ï¼‰', 'ç¾åœ¨ï¼ˆçŠ¶æ…‹ã€æ€§è³ªã€è€ƒãˆãªã©ï¼‰', 'éå»-ç¾åœ¨ï¼ˆç¿’æ…£ãªã©ï¼‰', 'æœªæ¥ï¼ˆäºˆå®šã€äºˆæ¸¬ã€é¡˜æœ›ã€ä»®å®šãªã©ï¼‰', 'ç¾åœ¨-æœªæ¥', 'æœ€è¿‘-æœªæ¥', 'éå»-æœªæ¥', 'æœ€è¿‘-ç¾åœ¨ï¼ˆç¿’æ…£ãªã©ï¼‰'}`
            - ï¼ˆãã‚“ãªã«ã‚ã‚‹ã®ã‹......ï¼‰
            - ã“ã‚Œã€åˆ†é¡ã§ãã‚‹ã®ã‹ï¼Ÿï¼Ÿ
            - ã€Œéå»ãƒ»ç¾åœ¨ãƒ»æœªæ¥ã€ã®3ã¤ã«é›†ç´„ã—ãŸããªã„ï¼Ÿ â†’ ã“ã‚Œã¯å¤§æ­¦å…ˆç”Ÿã‚‰ã¨ç›¸è«‡ã™ã‚‹å¿…è¦ãŒã‚ã‚Šãã†
                - ï¼ˆå‰ã¾ã§ã¯ãã†ã ã£ãŸæ°—ãŒã™ã‚‹ãŒ.....ã€å¤§æ­¦å…ˆç”Ÿã‚‰ã«ã¨ã£ã¦ã¯ã€Œã›ã£ã‹ããƒ©ãƒ™ãƒ«å¢—ã‚„ã—ãŸã®ã«.....ã€ã¨ã„ã†ã“ã¨ã«ãªã‚‰ãªã„ï¼Ÿï¼‰
            - ãã‚Œãã‚Œã®ãƒ©ãƒ™ãƒ«é »åº¦ã‚’è¦‹ã‚‹ â†’ ä½é »åº¦ãƒ©ãƒ™ãƒ«ã¯ç„¡è¦–ã—ã¦ã‚‚è‰¯ã„ã‹ã‚‚ï¼Ÿ
            - intention = ç™ºè¨€ã«å¯¾ã™ã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼Ÿ

- æ–¹é‡çš„ã«ã¯ã‚„ã¯ã‚Šã“ã®ã¾ã¾ã§è‰¯ã•ãã†
    - ã¨ã‚Šã‚ãˆãš10å€¤åˆ†é¡ã§ã€`scripts_time.tsv`ã‚’train/devç­‰ã«åˆ†å‰²ã—ã¦BERTã‚’å†å­¦ç¿’ã•ã›ã¦ã¿ã‚‹
    - ãã®çµæœã‚’è¦‹ã›ãªãŒã‚‰ä»Šå¹´åº¦åˆå›ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’ä¼ç”»ã™ã‚‹ï¼ˆ4æœˆä¸‹æ—¬ï¼‰

### 4/3(Fri)

#### tokenize_data.py
- ãã‚Œãã‚Œã®ãƒ©ãƒ™ãƒ«é »åº¦ã‚’è¦‹ã‚‹
    - `label_freq:      Counter({'ç¾åœ¨ï¼ˆçŠ¶æ…‹ã€æ€§è³ªã€è€ƒãˆãªã©ï¼‰': 29626, 'éå»': 12065, 'éå»-ç¾åœ¨ï¼ˆç¿’æ…£ãªã©ï¼‰': 5037, 'æœ€è¿‘ï¼ˆ1ã‹æœˆä»¥å†…ï¼‰': 3749, 'æœªæ¥ï¼ˆäºˆå®šã€äºˆæ¸¬ã€é¡˜æœ›ã€ä»®å®šãªã©ï¼‰': 2073, 'æœ€è¿‘-ç¾åœ¨ï¼ˆç¿’æ…£ãªã©ï¼‰': 182, 'éå»-æœ€è¿‘': 117, 'ç¾åœ¨-æœªæ¥': 74, 'éå»-æœªæ¥': 58, 'æœ€è¿‘-æœªæ¥': 13})`
    - ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–ã—ãŸã„ã®ã§matplotlibã‚’install
    - `pip install matplotlib`

    - æ™‚é–“ãƒ©ãƒ™ãƒ«ã®é »åº¦åˆ†å¸ƒã‚’èª¿ã¹ã‚‹ã®ã‚’é–¢æ•°åŒ–ã—ãŸ
        - `count_label_freq()`
            - [plt.savefig(bbox_inches = tight)](http://virsalus.hatenablog.com/entry/2015/01/19/120931)
            - [mpl.rcParams['font.family'] = 'Meiryo']()
            - [plt.xticks(rotation = 270)](https://www.delftstack.com/ja/howto/matplotlib/how-to-rotate-x-axis-tick-label-text-in-matplotlib/)

    - æ¾ç”°ã•ã‚“ã€Œã¨ã‚Šã‚ãˆãšã¯ï¼Œå¤šã„æ–¹ã‹ã‚‰5ãƒ©ãƒ™ãƒ«ã ã‘ã‚’ç›¸æ‰‹ã«ã™ã‚‹æ–¹å‘ã§ã„ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã­ï¼ã»ã‹ã¯ã©ã“ã‹ã«ãƒãƒ¼ã‚¸ã™ã‚‹ã‹ï¼Œç„¡è¦–ã™ã‚‹ã‹ï¼Œãã®ã‚ãŸã‚Šã¯å¤§æ­¦ãƒãƒ¼ãƒ ã¨ç›¸è«‡ã—ã¾ã—ã‚‡ã†ï¼ã€
        - ã‚ã‹ã‚‹
        - ã¨ã‚Šã‚ãˆãš10å€¤åˆ†é¡ã¨5åˆ†é¡ï¼ˆå‰Šã‚Šï¼‰ã‚’è©¦ã—ã¦ã¿ã‚‹ã‹

### 4/6(Mon)
#### tokenize_data.pyã®ç¶šã
- Mecabåˆ†å‰²ã‚’ã—ãŸã„
    - Mecab-python, ã†ã¾ãå‹•ã‹ã™ã®ã‚€ãšã„ã‚“ã ã‚ˆãªã€œã¨æ€ã£ã¦ãŸã‘ã©ã€BertJapaneseTokenizerã§ã„ã‘ã‚‹ï¼Ÿï¼Ÿ
- ä¸Šã®ãƒªãƒ³ã‚¯å…ˆã®tensorflowã‚’ç”¨ã„ãŸdata tokenizeã‚³ãƒ¼ãƒ‰ã‚’copy

### 4/7(Tue)
#### æ˜¨æ—¥ã«å¼•ãç¶šãtokenize_data.py
- ã‚ã‚“ã©ãã•ã„ã‹ã‚‰å…ˆã«MeCabåˆ†å‰²ãŒã¡ã‚ƒã‚“ã©ã§ãã‚‹ã‹ã¿ãŸã„
- ãã‚‚ãã‚‚1è¡Œã”ã¨ã®å‡¦ç†ã§ã¯ãªãã€pandasã§ä¸€æ°—ã«å‡¦ç†ã—ãŸæ–¹ãŒè‰¯ã•ãã†ï¼ˆtfã‚’ç”¨ã„ãŸãƒ‡ãƒ¼ã‚¿åˆ†å‰²ãŒDataFrameä¸Šã§ã§è¡Œã‚ã‚Œã¦ã„ã‚‹ãŸã‚ï¼‰
    - `pip install pandas`

- **train / dev / testã®åˆ†å‰²ã‚’file_idå˜ä½ã§è¡Œã†**
    - ã‹ã‚‰ã€ä¸Šã®ãƒªãƒ³ã‚¯å…ˆã®ã‚³ãƒ¼ãƒ‰ã‚’ãã‚“ãªå˜ç´”ã«ä½¿ãˆã‚‹ã‚ã‘ã§ã¯ãªã„
        - file_id ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒãã‚Œã£ã½ã„ã§ã™ã­ï¼226ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚ã‚‹ã®ã§ã™ã­ï¼`200 / 13 / 13` ãã‚‰ã„ã‹ï¼Œã‚‚ã†ã™ã“ã— dev / test ãŒå¤šã„ `150 / 38 / 38` ã‹ï¼Œãã‚Œãã‚‰ã„ã§ã—ã‚‡ã†ã‹ï¼by æ¾ç”°ã•ã‚“

#### æ¾ç”°ã•ã‚“ã¨æ‰“ã¡åˆã‚ã›
- æœ€åˆã‹ã‚‰5ãƒ©ãƒ™ãƒ«ã§ã‚„ã£ã¦ã¿ã‚‹

- ä»–ã®annotationãƒ©ãƒ™ãƒ«ã«ã¤ã„ã¦ã®åˆ†å¸ƒå¯è¦–åŒ–ã‚‚ã—ã¦ãŠãï¼Ÿï¼ˆãªã‚“ã‹ã‚„ã£ã¦ã‚‹æ„Ÿã‚’å‡ºã™.....ï¼‰
    - ç†æƒ³ã¯RAIDENã§å­¦ç¿’å›ã—ã¦ã‚‹ã¨ãã«ã“ã®åˆ†å¸ƒå¯è¦–åŒ– & ã‚¹ãƒ©ã‚¤ãƒ‰ä½œæˆ

### 4/8(Wed)
- ã¨ã‚Šã‚ãˆãšæ–¹è¨€ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«ã‚’ç„¡ç†ã‚„ã‚Šfixã•ã›ã¦ã“ã£ã¡ã«å–ã‚Šæ›ã‹ã‚‹

#### extract_data.pyã§idåŒ–ã—ãŸtimelabelåˆ—ã‚’ä½œæˆã™ã‚‹
- `./data/script_time.tsv`ã‚’ãã†ã„ã†ãƒ‡ãƒ¼ã‚¿ã«ç½®ãæ›ãˆã‚‹
    - ã¤ã„ã§ã«ã€ã“ã“ã§5å€¤ã«æ¸›å°‘ã•ã›ã‚‹......ï¼Ÿ
    - `{'éå»': '0', 'éå»-æœ€è¿‘': '1', 'æœ€è¿‘ï¼ˆ1ã‹æœˆä»¥å†…ï¼‰': '2', 'ç¾åœ¨ï¼ˆçŠ¶æ…‹ã€æ€§è³ªã€è€ƒãˆãªã©ï¼‰': '3', 'éå»-ç¾åœ¨ï¼ˆç¿’æ…£ãªã©ï¼‰': '4', 'æœªæ¥ï¼ˆäºˆå®šã€äºˆæ¸¬ã€é¡˜æœ›ã€ä»®å®šãªã©ï¼‰': '5', 'ç¾åœ¨-æœªæ¥': '6', 'æœ€è¿‘-æœªæ¥': '7', 'éå»-æœªæ¥': '8', 'æœ€è¿‘-ç¾åœ¨ï¼ˆç¿’æ…£ãªã©ï¼‰': '9'}`
    - å‰Šã‚‹ã®ã¯`'æœ€è¿‘-ç¾åœ¨ï¼ˆç¿’æ…£ãªã©ï¼‰': 182, 'éå»-æœ€è¿‘': 117, 'ç¾åœ¨-æœªæ¥': 74, 'éå»-æœªæ¥': 58, 'æœ€è¿‘-æœªæ¥': 13`
    - `1, 6, 7, 8, 9`

`!head ./data/script_time.tsv`
```id	file_id	script	time    time_id
148177	1	ç§ä»¥å¤–ã¯ã¿ã‚“ãªæ±äº¬ã®æ–¹ãªã‚“ã§ã™ã‹ã­ã¿ãªã•ã‚“	ç¾åœ¨ï¼ˆçŠ¶æ…‹ã€æ€§è³ªã€è€ƒãˆãªã©ï¼‰	3
3	1	ä¸­å¤®åŒºã§ã™ã¯ã„	ç¾åœ¨ï¼ˆçŠ¶æ…‹ã€æ€§è³ªã€è€ƒãˆãªã©ï¼‰	3
4	1	ç§æ–‡äº¬åŒºã§ã™	ç¾åœ¨ï¼ˆçŠ¶æ…‹ã€æ€§è³ªã€è€ƒãˆãªã©ï¼‰	3
142715	1	ç§ã¯åƒè‘‰çœŒã§ã™ã€‚	ç¾åœ¨ï¼ˆçŠ¶æ…‹ã€æ€§è³ªã€è€ƒãˆãªã©ï¼‰	3
```
- ã¡ã‚‡ã†ã©ãã‚Šã®è‰¯ã„æ•°å­—ã«ãªã£ãŸ

#### tokenize_data.py
- updateã•ã‚ŒãŸ`./data/script_time.tsv`ã®time_idåˆ—ã‚’labelã¨ã—ã¦å‚ç…§
- ã¨ã‚Šã‚ãˆãšload_dataset()ã¾ã§ã¯å‹•ã„ãŸã£ã½ã„ï¼Ÿ

### 4/21(Tue)
- ãƒã‚¸ã§ã—ã°ã‚‰ãæ”¾ç½®ã—ã¦ãŸãª.......

- RAIDENã«å®Ÿè¡Œç’°å¢ƒã‚’æ•´ãˆã‚‹å¿…è¦ãŒã‚ã‚‹
    - https://io-lab.esa.io/posts/1047
    - è‰²ã€…é¢å€’ã£ã½ã„.......

- ç’°å¢ƒã¯condaã§ä½œã‚‹ã®ãŒè‰¯ã„ï¼Ÿ
    - æ¸…é‡ã•ã‚“ã¯pyenvã§ä½œã£ã¦ã„ã‚‹ï¼Ÿã§ã‚‚çµæ§‹å‰ã®è¨˜äº‹ã ã‹ã‚‰ãª.....
- ã‚³ãƒ³ãƒ†ãƒŠã§ã‚„ã‚‹ã®ãŒè‰¯ã„ï¼Ÿï¼Ÿ
    - äººã«èãã®ãŒä¸€ç•ªé€Ÿãã†ãªãã‚‚ã—ãªã„ã§ã‚‚ãªã„......

- https://files.esa.io/uploads/production/attachments/4896/2018/04/23/18306/c5294517-86c3-4ad6-8a54-b39319ed9414.pdf
    - æœ€åˆã¯ã“ã‚Œã‚’è¦‹ã¦ã‚„ã‚‹ã®ãŒä¸€ç•ªã„ã„ã‚‰ã—ã„
    - Hands on #2ã‚ãŸã‚ŠãŒå‚è€ƒã«ãªã‚‹ã‹ï¼Ÿ
    - ãªã‚“ã‹å¤‰ã ã¨æ€ã£ãŸã‚‰ã€`after login to the container`ã£ã¦æ›¸ã„ã¦ã‚ã‚‹
        - zshã«å¤‰ãˆãŸã‘ã©ã€æ™®é€šã«bashã§ã‚„ã£ãŸæ–¹ãŒæ¥½ãã†...
            - ã ã‘ã©ã€.bashrcã‚’rmã—ã¦ã—ã¾ã£ãŸ.......
            - [./bash_projileã‚„.bashrcã®å¤§å…ƒã¯/etc/skelã«ã‚ã‚‹](https://qiita.com/shyamahira/items/260862743e4c9794b5d2)ã®ã§ãã“ã‹ã‚‰copyã—ã¦ãã¦è§£æ±º
    
    - esaã®ã€Œfairseqã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¾ã§ã€ã£ã¦æ‰€ã‚’è¦‹ã‚‹
        - fairseq->transformerã«ã™ã‚Œã°è‰¯ã„ã‚ã‘ã ã—è¡Œã‘ãã†ï¼Ÿ
        - `# ã‚³ãƒ³ãƒ†ãƒŠã«å…¥ã‚Šï¼Œç’°å¢ƒå¤‰æ•°ãªã©ã®è¨­å®šã‚’ã™ã‚‹`ã®éƒ¨åˆ†ã¯å®Ÿè¡Œæ¸ˆ
        - `#cuda10ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–ã‚’ã™ã‚‹`ã‚ãŸã‚Šã‹ã‚‰å¤‰ãˆã‚‹å¿…è¦ãŒã‚ã‚Šãã†
            - ã¨ã‚Šã‚ãˆãšä»Šã‚ã‚‹dementiaç’°å¢ƒã«`source dementia/bin/activate`ã§ãƒ­ã‚°ã‚¤ãƒ³ã—ãŸä¸Šã§ã€`pip install torch torchvision`ã‚’ã—ã¦ã¿ã‚‹ï¼ˆLinux, cuda10ã‚’é¸ã‚“ã ã‚‰ãã‚Œã«ãªã£ãŸãŒlocalã§ã‚„ã£ãŸæ™‚ã¨åŒã˜ã§ã¯.....ï¼Ÿï¼‰
                - ãªã‚“ã‹ã‚ã£ã¡ã‚ƒRetryã—ã¦ã‚‹......
                - æœ€çµ‚çš„ã«`Could not find a version that satisfies the requirement torch (from versions: )No matching distribution found for torch`ã¨æ€’ã‚‰ã‚ŒãŸ
            - ã‚„ã£ã±ã‚Šserverä¸Šã§æ–°ã—ãç’°å¢ƒä½œã£ãŸæ–¹ãŒè‰¯ã„ã‚“ã˜ã‚ƒãªã„ã‹......ï¼Ÿ
                - ä¸€ã‹ã‚‰ã€Œdementia_cuda10ã€ç’°å¢ƒã‚’ä½œã‚ã†ã¨ã—ãŸã‚‰ã€`python3-venv`ãŒãªã„ã¨æ€’ã‚‰ã‚ŒãŸ
                - ã‚“ã‚“......
                - condaã§ä½œã‚‹ã‹...ï¼Ÿ
                - condaã®installã‹ã‚‰å§‹ã¾ã‚‹
                    - æ¸…é‡ã•ã‚“ã¯minicondaã‚‰ã—ã„ã®ã§minicondaã‚’installã™ã‚‹
                    - ã“ã‚Œæœ€æ–°ã®ã ã¨py=3.7ã«ãªã‚‹ã£ã½ã„ã‘ã©ãã‚Œã§ã„ã„ã®ã‹ãª.......
                - miniconda installã—ãŸãã¨æ€ã£ã¦conda createã¨ã‹ã‚„ã£ã¦ã‚‚not foundã¨æ€’ã‚‰ã‚Œã‚‹
                - Installationã«PATHã«é€šã›ã¨æ›¸ã„ã¦ã‚ã‚‹ã‹ã‚‰PATHã‚’è¦‹ãŸã‘ã©ã€æ€ã£ãŸä»¥ä¸Šã«PATHè‰²ã€…é€šã£ã¦ã‚‹ãªï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿâ†’ã‚ˆãèª­ã‚“ã ã‚‰ã€Œinstall shell scriptã¯è‡ªå‹•çš„ã«pathã‚’é€šã—ã¦ãã‚Œã¾ã™ã€ã£ã¦æ›¸ã„ã¦ãªã„ã‹ï¼Ÿ
                    - condaã¨ã‹ã¡ã‚ƒã‚“ã¨æ›¸ã„ã¦ãªã„ï¼Ÿï¼Ÿ
                    - ã‚ã€`.bashrc`ã«minicondaã¸ã®pathã‚’æ›¸ã„ã¦ãã‚Œã¦ã‚‹ã®ã­......

                - `conda create -n cuda10.0 py=3.6`ã‚’è©¦ã—ã«ã‚„ã£ã¦ã¿ã‚‹
                    - py=3.6ã§ã„ã„ã®ã‹......
                    - `Collecting package metadata`ã‹ã‚‰å‹•ã‹ãªã„.....
                    - ãˆï¼Ÿï¼Ÿanacondaã®HTTPã«ç¹‹ãŒãªã„ã¨ã„ã‘ãªã„ã®ï¼Ÿï¼Ÿ
                        - ã€Œã‚³ãƒ³ãƒ†ãƒŠã®ä¸­ã§ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã«ç¹‹ãã€ã‚’ã‚„ã‚“ãªã„ã¨ã„ã‘ãªã„ã£ã¦ã“ã¨ï¼Ÿï¼Ÿ
                        - ãªã‚“ãªã‚“ï¼Ÿï¼Ÿ
                        - è¦‹ãŸæ„Ÿã˜æ—¢ã«ã€Œbaseã€ã¨ã„ã†ç’°å¢ƒã«å…¥ã£ã¦ã‚‹ã½ã„ã®ã§ã‚‚ã†ãã“ã«installã—ã¦ã„ã£ã¡ã‚ƒã†ï¼Ÿ
                        - conda install pytorch torchvision cudatoolkit=10.0 -c pytorch

### 4/23(Tue)
- éˆ´æœ¨ã•ã‚“ã¨é›‘è«‡
    - éˆ´æœ¨ã•ã‚“ã¯projectã”ã¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«python3ã®venvã§ä»®æƒ³ç’°å¢ƒä½œã£ã¦ã‚‹
        - ãƒ­ã‚°ã‚¤ãƒ³ãƒãƒ¼ãƒ‰ã ã‹ã‚‰pipç­‰ãŒå‹•ã‹ãªã‹ã£ãŸ
        - GPUãƒãƒ¼ãƒ‰ã ã¨4æ™‚é–“ã—ã‹ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ã§ããªã„ã®ã§ã€é•·æ™‚é–“ãªã‚‰ã‚¸ãƒ§ãƒ–ã‚’æŠ•ã’ãªã„ã¨ã„ã‘ãªã„
    - esaã«æ›¸ã„ã¦ã‚ã‚‹`setup.py`ã‚’sourceã«ã—ã¨ãå¿…è¦ãŒã‚ã‚‹ï¼Ÿï¼ˆã“ã‚Œã¯ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã—ã¦å¤§ä¸ˆå¤«ï¼‰
    - IP adressãŒCPUãƒãƒ¼ãƒ‰ã¨GPUãƒãƒ¼ãƒ‰ã§é•ã†
        - For PPCã£ã¦æ›¸ã„ã¦ã‚‹ã®ãŒCPUãƒãƒ¼ãƒ‰
    - ã€Œã‚³ãƒ³ãƒ†ãƒŠã®ä¸­ã§ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã«ç¹‹ãã€ & ã€Œã‚³ãƒ³ãƒ†ãƒŠå†…ã§venvç’°å¢ƒã‚’ä½¿ã†ã€è©¦ã—ã¦ã¿ã‚‹ï¼ 

### 4/24(Fri)
- ã€Œã‚³ãƒ³ãƒ†ãƒŠã®ä¸­ã§ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã«ç¹‹ãã€ã‚’ã‚„ã‚‹
    - `setup.py`æ›¸ã„ã¦bash_profileã«å®Ÿè¡Œã™ã‚‹æ—¨æ›¸ã
        - `Collecting package metadata...`ã¯ã„ã„æ„Ÿã˜ã«è¡Œã£ã¦ã‚‹ã£ã½ã„ãŒã€py=3.6ã¨ã‹3.7ã¨æŒ‡å®šã—ã¦ã‚‚PackagesNotFoundErrorã¨è¨€ã‚ã‚Œã‚‹

- ã€Œã‚³ãƒ³ãƒ†ãƒŠå†…ã§venvç’°å¢ƒã‚’ä½¿ã†ã€
    - `.bashrc`ã«æ›¸ã„ã¦ã‚ã‚‹condaã¸ã®PATHé€šã—ã‚’ä¸€æ—¦ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ã€venvç’°å¢ƒã‚’ä½¿ã†
    - `pip install torch torchvision --user`ã‚’è©¦ã—ã¦ã¿ã‚‹
        - `Permission denied error`ãŒå‡ºãŸ
        - `--user` optionãŒå¿…è¦
        - ãªã‚“ã‹ã“ã‚Œã¾ã§ã¤ã¾ã¥ã„ã¦ã„ãŸã¨ã“ã‚ã¯ã‚ã‚‹ç¨‹åº¦ã„ã‘ã¦ã‚‹ã£ã½ã„ãŒã€ã‚ˆãèª­ã‚€ã¨site-packagesã¨ã‹ãŒã€Œpython3.5ã€ã¨æ›¸ã„ã¦ã‚ã‚‹
        - ãªã‚“ã§ï¼Ÿ

    - globalã«å‚ç…§ã™ã‚‹python3ãŒpython3.5.2ã£ã½ã„ï¼Ÿï¼Ÿ
    - ãˆã€œã€œ
        - ã‚„ã£ã±minicondaã®ç’°å¢ƒä½¿ã†ï¼Ÿ
        - minicondaã®(base)ç’°å¢ƒã«å…¥ã£ã¦ã‚‚ã€python3ã§å®Ÿè¡Œã•ã‚Œã‚‹ã®ã¯python3.5.2ãªã®ã ãŒ......
        - `~/miniconda3/bin/python3.7`ã‚’å®Ÿè¡Œã™ã‚‹ã¨Python3.7.6ãŒèµ·å‹•ã•ã‚Œã‚‹ï¼ˆãã‚Œã¯ãã†ï¼‰

        - [PYTHONUSERBASE](https://qiita.com/ronin_gw/items/cdf8112b61649ca455f5)ãªã‚‹ç’°å¢ƒå¤‰æ•°ãŒã‚ã‚‹ã‚‰ã—ã„
            - è¨­å®šã—ãŸãŒã€ãªãœã‹miniconda3ã®ä¸­ã«ã‚‚python3.5ãŒã‚ã‚Šã€é ‘ãªã«python3.7ã«installã—ã¦ãã‚Œãªã„
            - ãªã‚“ã§ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ

    - `conda list`ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€pythonã¯3.7.6ã ã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹
        - æ™®é€šã«py=ã¨ã‹æŒ‡å®šã—ãªã‘ã‚Œã°ã„ã„ã®ã§ã¯ï¼Ÿã¨ã„ã†ã‹ã€ãŸã¶ã‚“python=3.6ã¨ã‹ãªã‚‰ã„ã‘ãŸï¼Ÿï¼Ÿ
        - ã„ã‘ãŸã€œã€œã€œã€œ

#### ã‚µãƒ¼ãƒä»®æƒ³ç’°å¢ƒæ§‹ç¯‰(dementia_cuda10)
- condaã«ã‚ˆã‚‹æ ¼é—˜ã®è·¡
    - `conda activate cuda10.0`
    - `pip install tensorflow` ï¼ˆç¾versionã¯gpuã¨ã‹åŒºåˆ¥ã—ãªãã¦è‰¯ã„ã£ã½ã„......ï¼Ÿï¼‰
        - cudaã«PATHé€šã™å¥´ã¯...ï¼Ÿ
        - ã¦ã„ã†ã‹ã‚ã‚Œã€ã¾ãŸpython3.5ã®ç’°å¢ƒã«installã—ã¦ãªã„.....ï¼Ÿ
        - condaã§installã—ãŸã‚‰è‰¯ã„.....ï¼Ÿ
    - `conda install pytorch torchvision cudatoolkit=10.0 -c pytorch`
    - `conda install -c anaconda tensorflow-gpu`
        - tensorflow==2.0.0 installã§ãã¦ã‚‹ã—ã€å¤§ä¸ˆå¤«ãã†ã§ã¯ã‚ã‚‹.....
    - `conda install torchvision`
        - build py36_0ã¨ã‚‚æ›¸ã„ã¦ã‚‹ã—å¤§ä¸ˆå¤«ãã†......ï¼Ÿ
    - `conda install transformers`
        - ã“ã‚Œã¯PackagesNotFoundErrorãŒå‡ºã‚‹
    - `home/src`directoryã‚’æ–°ã—ãä½œã‚Šã€ãã“ã«transformersã€€repositoryã‚’ç½®ã
        - ã„ã‚„ã€çµå±€`pip install .`ã‚’å®Ÿè¡Œã§ããªã„ã¨å³ã—ã„......ï¼Ÿ

- `venv`æ ¼é—˜ã«æˆ»ã‚‹
    - python3.5ã«ãªã£ã¡ã‚ƒã†ã‚„ã¤ã‚’éˆ´æœ¨mã•ã‚“ã«èã
        - ã‚³ãƒ³ãƒ†ãƒŠã«å…¥ã£ã¦ã„ã‚‹pythonãŒ3.5ã«ãªã£ã¦ã—ã¾ã£ã¦ã„ã‚‹
    - `nvcr-pytorch-2003`ã®ã‚³ãƒ³ãƒ†ãƒŠï¼ˆpython3.6)å†…ã§ã‚„ã‚‹ã¨è‰¯ã„ï¼Ÿ
        - `cat containor-info`
    - ã‚„ã£ãŸã€œã€œã€œã§ããŸã€œã€œã€œ

- `dementia_cuda10`ç’°å¢ƒè¨­å®š
    - `pip install transformers==2.4.1`
    - `pip install https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl`
    - `pip install torchvision`
    - `pip install mecab-python3`

- **`python sample.py`ãŒå‹•ã„ãŸï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼**
    - ã‚‚ã†çµ‚ã‚ã£ã¦ã„ã„ã‹ï¼ˆãƒ€ãƒ¡ï¼‰

### 5/19(Tue) 
- 1ãƒ¶æœˆãã‚‰ã„çµŒã¨ã†ã¨ã—ã¦ã„ãŸ......ã“ã‚Œã¯ã„ã‹ã‚“

- ç§‘ç ”è²»å¥¨åŠ±è²»ã®ã‚¢ãƒ¬
    - ã€Œã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ã§äººæ‰‹è©•ä¾¡ã™ã‚‹ãï¼ã€ã¨è¨€ã£ã¦ã„ãŸã‘ã©ã€å€‹äººæƒ…å ±ã¨ã‹å¤§ä¸ˆå¤«ãªã‚“ã ã£ã‘ï¼Ÿ
    - [ç†ç ”ã®ç ”ç©¶å€«ç†ã®ã‚„ã¤](https://www.riken.jp/medialibrary/riken/about/reports/ethics/ethics-bylaw_20190723.pdf)
        - ã€Œãƒ’ãƒˆã‚²ãƒãƒ ãƒ»éºä¼å­è§£æç ”ç©¶ä»¥å¤–ã®ç ”ç©¶ã«ä¿‚ã‚‹å€‹äººæƒ…å ±ç­‰ã®ä¿è­·ã€ã®ç¬¬7æ¡ã¨ã‹ãŒãã‚Œã£ã½ã„
            - åŒ¿ååŒ–ã¨ã‹ã™ã‚Œã°åŸºæœ¬çš„ã«ã¯è‰¯ã„
            - ã‘ã©ä½ã‚“ã§ã‚‹ã¨ã“ã‚ãŒã ã„ãŸã„ã‚ã‹ã‚‰ãªãã‚‚ãªã„ã®ã§ã€ãã®è¾ºã‚‚å°‘ã—å¿…è¦ã‹ã‚‚

- ã‚„ã‚‹ã“ã¨ã‚’æ•´ç†ã—ã‚ˆã†
    - åœŸæ—¥ã§å­¦ç¿’ã‚’å›ã—ãŸã„
        - å‰å‡¦ç†ã®å®Œé‚
            - MeCabã‚’ã‹ã‘ã‚‹
            - japanese-BERTã®ä¸­ã«å…¥ã£ã¦ã„ã‚‹tokenizerã§åˆ†ã‘ã‚‹
        - è©•ä¾¡ã‚’ã©ã†ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ¼ã‚¿ã®splitå•é¡Œï¼‰
            - **train / dev / testã®åˆ†å‰²ã‚’file_idå˜ä½ã§è¡Œã†**
            - file_idã§åˆ†å‰²
            - 226ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚ã‚‹ â†’ `150 / 38 / 38` ã§åˆ†å‰²ã™ã‚‹

- ã‚ã®ã‚µã‚¤ãƒˆã«å¾“ã£ã¦ã‚„ã‚‰ãªã„æ–¹ãŒè‰¯ã„æ°—ãŒã—ã¦ããŸ, è‡ªåˆ†ã§ã‚†ã£ãã‚Šã‚„ã£ã¦è¡Œã£ãŸæ–¹ãŒè‰¯ã•ãã† -> [ã“ã‚Œ](https://qiita.com/nekoumei/items/7b911c61324f16c43e7e)ã¯å‚è€ƒã«ãªã‚‹ã‹ã‚‚
    - python ./tokenize_data.pyã‚’å®Ÿè¡Œã—ã‚ˆã†ã¨ã—ãŸã‚‰ã‚¨ãƒ©ãƒ¼ã‚’tensorflowãŒãªã„ã¨è¨€ã‚ã‚ŒãŸã®ã§ã€`pip install tensorflow-gpu`ã‚’ã—ã¦ã¿ã‚‹
        - ãªã‚“ã‹PATHãŒé€šã£ã¦ãªã„ã¨ã‹ã£ã¦æ€’ã‚‰ã‚ŒãŸã‹ã‚‰ä¸€å¿œ`/uge_mnt/home/abe-k/.local/bin`ã‚’exportã§PATHã«é€šã™
    - ã€ŒãŠå‰ã¯ä½•ã‚’è¨€ã£ã¦ã„ã‚‹ã‚“ã ã€çš„ãªã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸ
        - > OSError: Model name 'bert-base-japanese' was not found in tokenizers model name list (bert-base-japanese, bert-base-japanese-whole-word-masking, ...)
        - æ¾ç”°ã•ã‚“ã‹ã‚‰ã€Œmodelã®ç½®ãå ´æ‰€ãŒå¤‰ã‚ã£ãŸã‚‰ã—ã„ã€ã¨ã®æƒ…å ±ã€upgradeã—ãŸã‚‰å‹•ãã‚ˆã†ã«ãªã£ãŸ

- `tokenize_data.py`tokenizeã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸ
    - tokenizeã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã„ãŸä¸Šã§ã€train, dev, testã«åˆ†ã‘ãŸã„

#### æ˜æ—¥ã‚„ã‚‹ã“ã¨
- æ—©ãtrain, dev, testã«åˆ†ã‘ã‚ˆã†ã­

- modelã®fine-tuningã‚’ã©ã†ã™ã‚‹ã‹ã«é–¢ã—ã¦ã¯ãªã‚“ã‹è‰²ã€…ãªã‚µã‚¤ãƒˆãŒå‡ºã¦ãã¦æ··ä¹±ã—ã¦ã„ã‚‹ã€‚çš†è‡ªå·±æµã§ã‚„ã£ã¦ã‚“ãª......
    - GLEU taskã‚’è§£ãæµã‚Œã«ã¬ã‚‹ã£ã¨æ–°ã—ã„taskã‚’æŒ¿å…¥ã™ã‚‹ã€ã¨ã„ã†ã“ã¨ã‚’ã‚„ã£ã¦ã„ã‚‹äººã‚‚ã„ã‚‹(https://qiita.com/kenta1984/items/7f3a5d859a15b20657f3)ã€ãŒGLEUã®æ¦‚å¿µã‚’å´©å£Šã•ã›ã¦ã„ãã†ãªã®ã§ã‚ã‚“ã¾ã‚Šã‚„ã‚ŠãŸããªã„ï¼ˆç°¡å˜ãã†ã ã‘ã©.....ï¼‰

- ï¼ˆä½™è«‡ï¼‰rikenã‚µãƒ¼ãƒã®ç«¯æœ«ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰ãˆãŸã„ï¼ˆæœªè§£æ±ºï¼‰
    - https://qiita.com/wildeagle/items/5da17e007e2c284dc5dd
        - `~/.bashrc`ã«æ›¸ã„ãŸã‚‰ã€ä»®æƒ³ç’°å¢ƒã‚’activateã™ã‚‹ã¾ã§ã¯ã„ã„ã®ã ãŒactivateã—ãŸå¾Œãƒ€ãƒ¡ã«ãªã‚‹
        - ã†ã€œã‚€

- ï¼ˆä½™è«‡2ï¼‰kiyonoã•ã‚“ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã«å¾“ã£ã¦SFTPã—ãŸã„ï¼ˆ**è§£æ±º**ï¼‰
    - æ›°ãã€ä½¿ã£ã¦ã„ã‚‹ã‚½ãƒ•ãƒˆå + SFTPã¨æ¤œç´¢ã™ã‚Œã°è‰¯ã„â†’ã§ã¦ããŸã®ãŒ[ã‚³ãƒ¬](https://qiita.com/ishimasar/items/1324af16e19a59b220d3) 
    - simpleãª`sample_sftp`ã¨ã„ã†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é–¢ã—ã¦ã¯ã†ã¾ãè¡Œã£ãŸãŒã€`dementia_dialogue`ã«é–¢ã—ã¦ã¯ã†ã¾ãã„ã‹ãªã„...
    - ã¨æ€ã£ãŸã‚‰, portã®å•é¡Œã ã£ãŸã£ã½ã„ï¼Ÿ
        - ã‚ã£ã¡ã‚ƒé ‘å¼µã£ã¦`dementia_cuda10`ã®è¨­å®šã¨ã‹downloadã—ã¦ãã‚Œã¦ã‚‹ã£ã½ã„...ã“ã‚Œå¤§ä¸ˆå¤«ã‹......

### 5/20(Wed)

#### ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
- åŠ¹ç‡çš„ã«ã‚„ã‚‹ã®ã¯è«¦ã‚ã¦ã€ã¨ã‚Šã‚ãˆãšè‡ªåˆ†ã§ã‚ã‹ã‚‹ã‚ˆã†ã«ã‚„ã£ã¦ã„ã“ã†...

- tokenizedã—ãŸscriptåˆ—ã‚’è¿½åŠ ã—ãŸ`./scripts_time.tsv.tok`ã‚’tmpãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¸€æ—¦ä¿å­˜â†’ãã‚Œã‚’åˆ†å‰²ã€ã¨ã„ã†ãµã†ã«ã™ã‚‹

- `./scripts_time.tsv.tok`ã‚’èª­ã¿è¾¼ã‚“ã§ã€file_idã§åˆ†å‰²
    - 226ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚ã‚‹ â†’ `150 / 37 / 37` ã§åˆ†å‰²ã™ã‚‹
        - train: 1 ~ 150
        - dev: 151 ~ 189
        - test: 190 ~ 226

- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«åˆ†å‰² â†’ å®Ÿéš›ã®æ–‡æ•°ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã£ãŸ
```
11019 ./data/test.tok
32816 ./data/train.tok
8715 ./data/valid.tok
----------------------
52550 total
```


## TODAY
### 5/22(Fri)
#### ãƒ¢ãƒ‡ãƒ«ä½œæˆ
- https://qiita.com/kenta1984/items/7f3a5d859a15b20657f3
- ã¡ã‚‡ã£ã¨é‚ªé“ã ãŒã€ã“ã‚Œã‚’å‚è€ƒã«ã—ã¦ã¿ã‚‹
    - transformersã®glue.pyã¨metrics/__init.pyã‚’ã„ã˜ã‚‹
    - ä»¥ä¸‹ã‚’å®Ÿè¡Œ
    ```run.sh
    DATA_DIR=/home/abe-k/dementia_dialogue/dementia_dialogue/data/
    OUTPUT_DIR=/home/abe-k/dementia_dialogue/dementia_dialogue/output

    python ~/src/transformers/examples/text-classification/run_glue.py \
    --data_dir=$DATA_DIR \
    --model_type=bert \
    --model_name_or_path=bert-base-japanese-whole-word-masking \
    --task_name=original \
    --do_train \
    --do_eval \
    --output_dir=$OUTPUT_DIR
    ```

- `run_glue.py`ã¯git cloneã—ãŸãƒªãƒã‚¸ãƒˆãƒªã®ä¸­ã®exampleã®éƒ¨åˆ†ã«ã‚ã‚‹ã£ã½ã„
    - `home/abe-k/src/`ä»¥ä¸‹ã«install ã™ã‚‹ï¼ˆversionç®¡ç†ã®ãŸã‚ï¼‰
    - `pip install -r ./examples/requirements.txt`

    - ä¸Šã®ã‚„ã¤ã‚’å‹•ã‹ã™å‰ã«ã€ãã‚‚ãã‚‚æ™®é€šã®glueãŒã†ã¾ãã„ãã®ã‹è©¦ã—ãŸã„...
        - `transformers/data`ã«glueï¼ˆwnliï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’installã—ã¦ã¿ã‚‹
         - localã«ä¸€æ—¦è½ã¨ã—ã¦ã‹ã‚‰`rsync`ã§ã‚µãƒ¼ãƒã«ã‚ã’ã‚ˆã†ã‹ã¨æ€ã£ãŸã‘ã©ã€ã¨ã‚Šã‚ãˆãš`wget https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FMNLI.zip?alt=media&token=50329ea1-e339-40e2-809c-10c40afff3ce`ã‚’è©¦ã—ã¦ã¿ã‚‹ â†’ ãƒ•ãƒªãƒ¼ã‚ºã—ã¦ã„ã‚‹ & ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…·åˆãŒè¡¨ç¤ºã•ã‚Œãªã„ã€‚**wgetã¯ä½¿ã‚ãªã„æ–¹ãŒè‰¯ã•ãã†**
        - **rsyncã§é€ã‚‹æ™‚ã€ã‚µãƒ¼ãƒå´ã®pwdã§å‡ºã¦ãã‚‹`uge_mnt`ã¯ã„ã‚‰ãªã„**

    - ä»¥ä¸‹ã‚’å®Ÿè¡Œã™ã‚‹ã‚‚ã€FileNotFoundErrorãŒå‡ºã‚‹
    ```python examples/text-classification/run_glue.py \
    --data_dir=/data/WNLI \
    --model_type=bert \
    --model_name_or_path=bert-base-uncased \
    --task_name=wnli \
    --do_train \
    --do_eval \
    --output_dir=output/
    ```
    > FileNotFoundError: [Errno 2] No such file or directory: '/data/WNLI/cached_train_BertTokenizer_128_wnli.lock'
    - æ¤œç´¢ã—ã¦ã‚‚ã€1ä»¶ã‚‚HITã—ãªã„ã€‚ã‚ã‚Œãˆ.....ï¼Ÿ
        - examples/text-classificationã®ä¸­ã®README.mdã‚’è¦‹ãŸã‚‰ã€xnliã«ã¯xnliç”¨ã®scriptãŒã‚ã£ãŸã‚Šã€ä»–ã®glueã‚¿ã‚¹ã‚¯ã«ã‚‚ãã‚Œãã‚ŒsnippetãŒã‚ã£ãŸã‚Šã—ãŸã®ã§ãã‚Œã‚’å®Ÿè¡Œã—ãŸæ–¹ãŒè‰¯ã•ãã†ã€‚
    
    - â†‘ã‚’å®Ÿè¡Œã—ãŸã‚‰çµå±€src/transformersã®ä¸­èº«ã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹ã®ã§ã€ãã‚Œã‚’ã„ã˜ã‚‹
        - glue_tasks_num_labelsã¨ã‹ã¨è¨€ã‚ã‚Œã¦ã„ã‚‹

> 05/22/2020 05:46:39 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False 
    - GPUä½¿ã£ã¦ãªã„ãª.....

Traceback (most recent call last):
  File "/uge_mnt/home/abe-k/src/transformers/examples/text-classification/run_glue.py", line 108, in main
    num_labels = glue_tasks_num_labels[data_args.task_name]
KeyError: 'original'

- ä»¥ä¸‹ã¯ä¸Šã®ã‚¨ãƒ©ãƒ¼ã‹ã‚‰assertã•ã‚ŒãŸã‚‚ã®ã ã‹ã‚‰ä¸€æ—¦ç½®ã„ã¦ãŠã
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/uge_mnt/home/abe-k/src/transformers/examples/text-classification/run_glue.py", line 228, in <module>
    main()
  File "/uge_mnt/home/abe-k/src/transformers/examples/text-classification/run_glue.py", line 111, in main
    raise ValueError("Task not found: %s" % (data_args.task_name))
ValueError: Task not found: original

- ç›´ã—ãŸãŒã€ipdbã§ç¢ºã‹ã‚ã¦ã¿ã¦ã‚‚glue_tasks_num_labelsã«originalãŒå…¥ã£ã¦ã„ãªã„ğŸ¤”
> ipdb> glue_tasks_num_labels                                                                                                                                 
{'cola': 2, 'mnli': 3, 'mrpc': 2, 'sst-2': 2, 'sts-b': 1, 'qqp': 2, 'qnli': 2, 'rte': 2, 'wnli': 2}

- è€ƒãˆã‚‰ã‚Œã†ã‚‹å ´æ‰€ï¼ˆä»®æƒ³ç’°å¢ƒ`dementia_cuda10`ã®lib or git cloneã—ãŸãƒªãƒã‚¸ãƒˆãƒªï¼‰ã¯`original`ã‚’ä»˜ã‘åŠ ãˆãŸã¨æ€ã†ã‚“ã ã‘ã©ã€`import transformers`ã¯ã©ã“ã‚’ã¿ã¦ã‚‹ã‚“ã ï¼Ÿ
    - ã€Œtext-classificationå†…ã€ã¯è¦‹ã¦ã‚‹ã‘ã©ã€src/transformersã¯è¦‹ã¦ãªã•ãã†ï¼Ÿ
ipdb> sys.path                                                                                                              
['/home/abe-k/dementia_cuda10/lib/python3.6/site-packages', '/uge_mnt/home/abe-k/src/transformers/examples/text-classification', '/opt/conda/lib/python36.zip', '/opt/conda/lib/python3.6', '/opt/conda/lib/python3.6/lib-dynload', '', '/uge_mnt/home/abe-k/.local/lib/python3.6/site-packages', '/opt/conda/lib/python3.6/site-packages', '/opt/conda/lib/python3.6/site-packages/IPython/extensions', '/uge_mnt/home/abe-k/.ipython']
`/uge_mnt/home/abe-k/.local/lib/python3.6/site-packages`ã“ã“ã«ã‚‚transformersã‚ã‚‹ã€ã“ã‚Œã‚’importã—ã¦ã‚‹ã‹ã‚‚
    - ã“ã‚Œã‚’importã—ã¦ãŸ

- å‹•ã„ãŸã‘ã©ã€ã¾ãŸError
> Traceback (most recent call last):
  File "/uge_mnt/home/abe-k/src/transformers/examples/text-classification/run_glue.py", line 230, in <module>
    main()
  File "/uge_mnt/home/abe-k/src/transformers/examples/text-classification/run_glue.py", line 139, in main
    train_dataset = GlueDataset(data_args, tokenizer=tokenizer) if training_args.do_train else None
  File "/uge_mnt/home/abe-k/.local/lib/python3.6/site-packages/transformers/data/datasets/glue.py", line 111, in __init__
    output_mode=self.output_mode,
  File "/uge_mnt/home/abe-k/.local/lib/python3.6/site-packages/transformers/data/processors/glue.py", line 64, in glue_convert_examples_to_features
    examples, tokenizer, max_length=max_length, task=task, label_list=label_list, output_mode=output_mode
  File "/uge_mnt/home/abe-k/.local/lib/python3.6/site-packages/transformers/data/processors/glue.py", line 136, in _glue_convert_examples_to_features
    labels = [label_from_example(example) for example in examples]
  File "/uge_mnt/home/abe-k/.local/lib/python3.6/site-packages/transformers/data/processors/glue.py", line 136, in <listcomp>
    labels = [label_from_example(example) for example in examples]
  File "/uge_mnt/home/abe-k/.local/lib/python3.6/site-packages/transformers/data/processors/glue.py", line 131, in label_from_example
    return label_map[example.label]
KeyError: '3'

- ã“ã‚Œã£ã¦ã€glueã§æƒ³å®šã•ã‚Œã‚‹å¤šå€¤ãƒ©ãƒ™ãƒ«ã‚ˆã‚Šã‚‚å¤šã„ã‹ã‚‰...ï¼Ÿ
    - é ‘å¼µã‚Œã°ã©ã†ã«ã‹ã§ããã†ï¼Ÿ
    - Original_Processorã®, get_labeléƒ¨åˆ†ã‚’["0", "1"] â†’ ["0", ~, "5"]ã«æ‹¡å¼µ
    
